(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{404:function(t,s,a){"use strict";a.r(s);var n=a(47),e=Object(n.a)({},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"목차"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#목차","aria-hidden":"true"}},[t._v("#")]),t._v(" 목차")]),t._v(" "),a("p"),a("div",{staticClass:"table-of-contents"},[a("ul",[a("li",[a("a",{attrs:{href:"#목차"}},[t._v("목차")])]),a("li",[a("a",{attrs:{href:"#데이터-준비"}},[t._v("데이터 준비")])]),a("li",[a("a",{attrs:{href:"#빈도주의-t-검정"}},[t._v("빈도주의 t-검정")]),a("ul",[a("li",[a("a",{attrs:{href:"#독립표본-t-검정"}},[t._v("독립표본 t-검정")]),a("ul",[a("li",[a("a",{attrs:{href:"#독립성"}},[t._v("독립성")])]),a("li",[a("a",{attrs:{href:"#정규성"}},[t._v("정규성")])]),a("li",[a("a",{attrs:{href:"#등분산성"}},[t._v("등분산성")])])])]),a("li",[a("a",{attrs:{href:"#대응표본-t-검정"}},[t._v("대응표본 t-검정")]),a("ul",[a("li",[a("a",{attrs:{href:"#정규성-검정"}},[t._v("정규성 검정")])])])])])]),a("li",[a("a",{attrs:{href:"#베이지안-t-검정"}},[t._v("베이지안 t-검정")]),a("ul",[a("li",[a("a",{attrs:{href:"#베이지안-데이터-분석"}},[t._v("베이지안 데이터 분석")])]),a("li",[a("a",{attrs:{href:"#독립표본-t-검정"}},[t._v("독립표본 t-검정")])])])])])]),a("p"),t._v(" "),a("h2",{attrs:{id:"데이터-준비"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#데이터-준비","aria-hidden":"true"}},[t._v("#")]),t._v(" 데이터 준비")]),t._v(" "),a("p",[t._v("한 집단의 평균값과 다른 집단의 평균값의 차이가 명백하다는 점을 최대한 과학적인 방법으로 누군가에게 납득시켜야 할 때가 있습니다.\n아래에서는 빈도주의자(Frequentist)의 관점과 베이지안(Bayesian)의 과점에서 t-검정을 수행하는 방법을 살펴보고자 합니다.")]),t._v(" "),a("p",[t._v("데이터는 Kruschke, John. (2012) Bayesian estimation supersedes the t-test의 자료를 사용하도록 하겠습니다. 참고로 아래 데이터 준비 코드와 베이지안 t-검정 항목의 코드는 pymc3 튜토리얼의 코드를 참고했습니다.")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("drug "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("104")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("97")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("105")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("105")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("98")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("123")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("105")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("103")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("95")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("106")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("109")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("82")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("103")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("103")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("97")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("97")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("103")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("97")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("104")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("96")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("103")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("124")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("104")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nplacebo "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("99")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("97")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("104")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("105")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("88")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("104")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("103")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("97")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("99")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("99")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("101")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("102")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("99")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("99")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\ny1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("drug"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("array"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("placebo"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ny "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DataFrame"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("r_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("y1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" group"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("r_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'drug'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("drug"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'placebo'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("placebo"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br")])]),a("h2",{attrs:{id:"빈도주의-t-검정"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#빈도주의-t-검정","aria-hidden":"true"}},[t._v("#")]),t._v(" 빈도주의 t-검정")]),t._v(" "),a("p",[t._v("통계학 공부를 하며 접했던 다양한 자료들을 오랜만에 다시 찾아보고 나름대로 아래와 같이 정리를 해보았습니다.")]),t._v(" "),a("div",{staticClass:"tip custom-block"},[a("p",{staticClass:"custom-block-title"},[t._v("t-검정(t-test)")]),t._v(" "),a("p",[t._v("종속변수가 연속형이고 독립변수는 단독 범주형일 때 2개의 서로 다른 수준에 대해 짝을 이루지 않거나(독립표본 t-검정), 짝을 이루는(대응표본 t-검정) 표본들이 기본 가정(독립표본 t-검정의 경우 독립성/정규성/등분산성, 대응표본 t-검정의 경우 정규성)을 만족한다는 조건 하에 각각의 수준들이 유의적인 차이를 보이는지를 검정.")])]),t._v(" "),a("h3",{attrs:{id:"독립표본-t-검정"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#독립표본-t-검정","aria-hidden":"true"}},[t._v("#")]),t._v(" 독립표본 t-검정")]),t._v(" "),a("h4",{attrs:{id:"독립성"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#독립성","aria-hidden":"true"}},[t._v("#")]),t._v(" 독립성")]),t._v(" "),a("p",[t._v("독립변수에 따른 종속변수가 각 수준별로 짝을 이루고 있지 않아야 한다는 조건입니다(예를 들어 A 투약전/투약후, B 투약전/투약후...가 아닌 투약군 AB.../미투약군 CD...인 경우).")]),t._v(" "),a("h4",{attrs:{id:"정규성"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#정규성","aria-hidden":"true"}},[t._v("#")]),t._v(" 정규성")]),t._v(" "),a("p",[t._v("독립변수에 따른 종속변수는 정규분포를 만족해야 한다는 조건입니다. 주로 콜모고로프-스미노프(Kolmogorov-Smirnov) 검정을 통해 이를 밝혀내며, 파이썬에서는 statsmodels의 "),a("a",{attrs:{href:"https://www.statsmodels.org/dev/generated/statsmodels.stats.diagnostic.kstest_normal.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("statsmodels.stats.diagnostic.kstest_normal"),a("OutboundLink")],1),t._v(" 메소드를 사용할 수 있습니다.")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("sm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stats"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("diagnostic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kstest_normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("drug "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" placebo"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dist"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'norm'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pvalmethod"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'approx'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (0.22204128505832343, 9.700938640868548e-12)")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("div",{staticClass:"tip custom-block"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("콜모고로프-스미노프 검정은 정규분포 뿐만 아니라 수준별 표본들이 동일 분포를 따르는지를 검정하는데 사용할 수 있습니다.")])]),t._v(" "),a("div",{staticClass:"tip custom-block"},[a("p",{staticClass:"custom-block-title"},[t._v("TIP")]),t._v(" "),a("p",[t._v("여기선 statsmodels의 convenience method를 이용하였지만 scipy의 scipy.stats.kstest, scipy.stats.ks_2samp와 같은 메소드들을 사용할 수도 있습니다. 이 경우 정규분포를 fitting한 다음 cdf를 해당 메소드들의 argument롤 넘겨야 하는 등의 추가작업이 필요할 수 있습니다.")])]),t._v(" "),a("h4",{attrs:{id:"등분산성"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#등분산성","aria-hidden":"true"}},[t._v("#")]),t._v(" 등분산성")]),t._v(" "),a("p",[t._v("독립변수에 따른 종속변수는 각 수준별로 동일해야 한다는 조건(Homoscedasticity)입니다. 레빈(Levene) 검정을 이용하며, "),a("a",{attrs:{href:"https://github.com/statsmodels/statsmodels/blob/fbd36d7aff99b7c516ddefdd8d333a84d4bcc535/statsmodels/stats/weightstats.py#L1103",target:"_blank",rel:"noopener noreferrer"}},[t._v("statsmodels.stats.weightstats.test_equal_var"),a("OutboundLink")],1),t._v(" 메소드를 지원할 예정이지만, 현재는 2d에 대한 weight 구현 문제로 scipy의 "),a("a",{attrs:{href:"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.levene.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("scipy.stats.levene"),a("OutboundLink")],1),t._v(" 메소드를 사용해야 합니다.")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("sp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stats"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("levene"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("drug"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" placebo"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# LeveneResult(statistic=4.542872436860705, pvalue=0.03587638864722)")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("div",{staticClass:"danger custom-block"},[a("p",{staticClass:"custom-block-title"},[t._v("WARNING")]),t._v(" "),a("p",[t._v("레빈 검정 결과 등분산성을 만족하지 못하며 따라서 최종적으로 독립표본 t-검정을 수행할 때 아래와 같이 uservar argument에 'unequal' 속성을 부여해야 합니다. 참고로 '크다' 또는 '작다'의 판단이 아닌 '다르다'를 판단해야 하기 때문에 양측검정을 해야 하고 따라서 alternative argument는 'two-sided'가 되어야 합니다.")])]),t._v(" "),a("p",[t._v("따라서 최종 독립표본 t-검정 코드는 아래와 같습니다. "),a("a",{attrs:{href:"https://www.statsmodels.org/dev/generated/statsmodels.stats.weightstats.ttest_ind.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("statsmodels.stats.weightstats.ttest_ind"),a("OutboundLink")],1),t._v("를 참고하시기 바랍니다.")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# cf. Levene's test p-value < 0.05, H0: Equal Variance rejected. usevar should be 'pooled'.")]),t._v("\nsm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stats"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ttest_ind"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("drug"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" placebo"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" alternative"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'two-sided'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" usevar"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'unequal'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# (1.6221904572902277, 0.10975381983712841, 63.03889717357649)")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br")])]),a("p",[t._v("p-value가 0.1098로 어떤 기준을 따르느냐에(0.05? 0.10?) 따라 조금 애매하다면 애매할 수 있는 수치입니다.")]),t._v(" "),a("h3",{attrs:{id:"대응표본-t-검정"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#대응표본-t-검정","aria-hidden":"true"}},[t._v("#")]),t._v(" 대응표본 t-검정")]),t._v(" "),a("h4",{attrs:{id:"정규성-검정"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#정규성-검정","aria-hidden":"true"}},[t._v("#")]),t._v(" 정규성 검정")]),t._v(" "),a("p",[t._v("정규성 검정은 위에서 말씀드린 독립표본 t-검정의 경우와 동일합니다.")]),t._v(" "),a("p",[t._v("대응표본 t-검정의 경우 scipy의 "),a("a",{attrs:{href:"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("scipy.stats.ttest_rel"),a("OutboundLink")],1),t._v(" 메소드를 사용하면 됩니다.")]),t._v(" "),a("h2",{attrs:{id:"베이지안-t-검정"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#베이지안-t-검정","aria-hidden":"true"}},[t._v("#")]),t._v(" 베이지안 t-검정")]),t._v(" "),a("h3",{attrs:{id:"베이지안-데이터-분석"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#베이지안-데이터-분석","aria-hidden":"true"}},[t._v("#")]),t._v(" 베이지안 데이터 분석")]),t._v(" "),a("p",[t._v("베이지안 데이터 분석이 익숙하지 않으신 분들께는 "),a("router-link",{attrs:{to:"/blog/bayesian_data_analysis_introduction.html"}},[t._v("베이지안 데이터 분석")]),t._v(" 포스팅에 소개한 세 개의 영상을 먼저 보실 것을 추천드립니다.")],1),t._v(" "),a("h3",{attrs:{id:"독립표본-t-검정-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#독립표본-t-검정-2","aria-hidden":"true"}},[t._v("#")]),t._v(" 독립표본 t-검정")]),t._v(" "),a("p",[t._v("기본 가정은 앞서 살펴본 내용과 동일하며, 아래 코드를 보시면 스튜던트 t-분포의 파라메터가 되는 group1과 group2의 평균, 표준편차, 그리고 v에 대한 사전분포(믿음)들과 이에 따른 결정론적 사항들에 대해 정의한 내용을 보실 수 있습니다.")]),t._v(" "),a("p",[t._v("참고로 아래 코드의 작성자는 group1, group2 각각의 평균은 샘플 전체의 평균과 표준편차의 2배를 따르는 정규분포의 어딘가에 있을 것이라고 믿고 있고(정규분포이므로 봉우리 부분에 더 큰 믿음), 각각의 표준편차는 1부터 10까지 중 어딘가에 있을 것 같지만 그 중 어느 부분에 있을 확률이 더 높은지는 전혀 모르겠다고(균등분포) 믿고 있습니다.")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("μ_m "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nμ_s "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n\nσ_low "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\nσ_high "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    group1_mean "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'group1_mean'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" μ_m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("μ_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    group2_mean "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Normal"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'group2_mean'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" μ_m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sd"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("μ_s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    group1_std "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Uniform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'group1_std'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lower"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("σ_low"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" upper"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("σ_high"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    group2_std "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Uniform"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'group2_std'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lower"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("σ_low"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" upper"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("σ_high"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    λ"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" group1_std"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n    λ"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" group2_std"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v("\n\n    ν "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Exponential"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'ν_minus_one'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("29")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("\n    \n    diff_of_means "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Deterministic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'difference of means'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" group1_mean "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" group2_mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    diff_of_stds "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Deterministic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'difference of stds'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" group1_std "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" group2_std"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    effect_size "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Deterministic"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'effect size'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" diff_of_means "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqrt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("group1_std"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" group2_std"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("**")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br")])]),a("p",[t._v("그 다음 Likelihood를 정의합니다. 여기서 "),a("a",{attrs:{href:"https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo",target:"_blank",rel:"noopener noreferrer"}},[t._v("MCMC(Markov Chain Monte Carlo)"),a("OutboundLink")],1),t._v(" 방법을 통해 사전분포를 업데이트 하게 됩니다. 단순화시켜 말씀드리면 y1, y2에서 각각 관측된 표본들이(observed=yn) group1, group2 각각의 파라미터들에 대한 사전 믿음을 바탕으로 모델링한 분포와(여기서는 스튜던트-t) 일관된다면 이를 Accept하고 아니라면 Reject하는 과정을 거치며 각자의 목표 확률분포를 근사하게 되는 것입니다.")]),t._v(" "),a("blockquote",[a("p",[t._v("...(constructing a Markov chain to do Monte Carlo approximation).")])]),t._v(" "),a("p",[t._v("MCMC는 메트로폴리스-헤이스팅스, 깁스 샘플링 등의 랜덤워크 몬테카를로 알고리즘들을 사용합니다. 더 자세한 내용은 별도의 포스팅을 통해 다루어 보도록 하겠습니다. 다만 궁금하신 분들을 위해 차분하게 잘 설명된 자료를 남겨두자면 퀀토피안의 데이터 사이언티스트인 Thomas Wiecki의 "),a("a",{attrs:{href:"http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/",target:"_blank",rel:"noopener noreferrer"}},[t._v("MCMC sampling for dummies"),a("OutboundLink")],1),t._v("를 강력 추천드리고 싶습니다.")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    group1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("StudentT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'drug'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mu"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("group1_mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lam"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("λ"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nu"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ν"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" observed"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("y1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    group2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("StudentT"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'placebo'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" mu"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("group2_mean"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lam"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("λ"),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" nu"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("ν"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" observed"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("y2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("p",[t._v("이제 실제로 2000회의 샘플링을 수행합니다.")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" model"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    trace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cores"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br")])]),a("p",[t._v("아래는 Deterministic으로 정의한 부분에 대한 결과입니다. 물론 group1_mean, group2_mean, group1_std, group2_std, v_minus_one도 varnames 부분을 바꿔주기만 하면 아래와 유사한 방법으로 확인이 가능합니다.")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("pm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot_posterior"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("trace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" varnames"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'difference of means'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'difference of stds'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'effect size'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  ref_val"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  color"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#87ceeb'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("p",[a("img",{attrs:{src:"https://docs.pymc.io/_images/notebooks_BEST_21_0.png",alt:"posterior_deterministic"}})]),t._v(" "),a("p",[t._v("이제 우리는 경영진의 의문에 대해 이를 보다 효과적으로 설명하고, 쉽게 이해시키며, 어쩌면 설득 할 수도 있습니다. p-value가 뭔지도 모르는 사람에게 단순히 p-value가 얼마 이하라서 다르다, test 결과가 그렇다고 말 하는 것 보다, estimation의 결과를 보여주면서 우리의 사전 믿음이 어떠했고 사후 믿음은 얼마나 달라졌는지에 대한 정보도 함께 제공할 수 있는 보다 informative한 기법이기 때문입니다(인식론적 불확실성과 무작위적 불확실성의 구분).")]),t._v(" "),a("div",{staticClass:"tip custom-block"},[a("p",{staticClass:"custom-block-title"},[t._v("Why")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://docs.pymc.io/notebooks/BEST.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://docs.pymc.io/notebooks/BEST.html"),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("A more informative and effective approach for comparing groups is one based on estimation rather than testing, and is driven by Bayesian probability rather than frequentist. That is, rather than testing whether two groups are different, we instead pursue an estimate of how different they are, which is fundamentally more informative. Moreover, we include an estimate of uncertainty associated with that difference which includes uncertainty due to our lack of knowledge of the model parameters (epistemic uncertainty) and uncertainty due to the inherent stochasticity of the system (aleatory uncertainty).")])])])},[],!1,null,null,null);e.options.__file="t_test_in_bayesian_world.md";s.default=e.exports}}]);